{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d33f21e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T11:51:16.889247Z",
     "iopub.status.busy": "2024-07-06T11:51:16.888841Z",
     "iopub.status.idle": "2024-07-06T11:54:51.995555Z",
     "shell.execute_reply": "2024-07-06T11:54:51.994059Z"
    },
    "papermill": {
     "duration": 215.124974,
     "end_time": "2024-07-06T11:54:51.998714",
     "exception": false,
     "start_time": "2024-07-06T11:51:16.873740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "keras-cv 0.9.0 requires keras-core, which is not installed.\r\n",
      "keras-nlp 0.12.1 requires keras-core, which is not installed.\r\n",
      "tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\r\n",
      "apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\r\n",
      "google-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.1 which is incompatible.\r\n",
      "jupyterlab 4.2.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "momepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "osmnx 1.9.3 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.3.3 which is incompatible.\r\n",
      "ydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "jupyterlab 4.2.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "kfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\r\n",
      "kfp 2.5.0 requires requests-toolbelt<1,>=0.8.0, but you have requests-toolbelt 1.0.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing requirements for nest-asyncio: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/nest_asyncio-1.5.8.dist-info/METADATA'\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing requirements for nest-asyncio: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/nest_asyncio-1.5.8.dist-info/METADATA'\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing requirements for nest-asyncio: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/nest_asyncio-1.5.8.dist-info/METADATA'\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing requirements for nest-asyncio: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/nest_asyncio-1.5.8.dist-info/METADATA'\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing requirements for nest-asyncio: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/nest_asyncio-1.5.8.dist-info/METADATA'\u001b[0m\u001b[33m\r\n",
      "\u001b[0mCollecting chromadb\r\n",
      "  Downloading chromadb-0.5.3-py3-none-any.whl.metadata (6.8 kB)\r\n",
      "Collecting build>=1.0.3 (from chromadb)\r\n",
      "  Downloading build-1.2.1-py3-none-any.whl.metadata (4.3 kB)\r\n",
      "Requirement already satisfied: requests>=2.28 in /opt/conda/lib/python3.10/site-packages (from chromadb) (2.32.3)\r\n",
      "Requirement already satisfied: pydantic>=1.9 in /opt/conda/lib/python3.10/site-packages (from chromadb) (2.5.3)\r\n",
      "Collecting chroma-hnswlib==0.7.3 (from chromadb)\r\n",
      "  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\r\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /opt/conda/lib/python3.10/site-packages (from chromadb) (0.108.0)\r\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.25.0)\r\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.22.5 in /opt/conda/lib/python3.10/site-packages (from chromadb) (1.26.4)\r\n",
      "Collecting posthog>=2.4.0 (from chromadb)\r\n",
      "  Downloading posthog-3.5.0-py2.py3-none-any.whl.metadata (2.0 kB)\r\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (4.9.0)\r\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\r\n",
      "  Downloading onnxruntime-1.18.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.3 kB)\r\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (1.22.0)\r\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (1.22.0)\r\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\r\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.46b0-py3-none-any.whl.metadata (2.0 kB)\r\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (1.22.0)\r\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /opt/conda/lib/python3.10/site-packages (from chromadb) (0.19.1)\r\n",
      "Collecting pypika>=0.48.9 (from chromadb)\r\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.65.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (4.66.4)\r\n",
      "Requirement already satisfied: overrides>=7.3.1 in /opt/conda/lib/python3.10/site-packages (from chromadb) (7.4.0)\r\n",
      "Requirement already satisfied: importlib-resources in /opt/conda/lib/python3.10/site-packages (from chromadb) (6.1.1)\r\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (1.60.0)\r\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\r\n",
      "  Downloading bcrypt-4.1.3-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\r\n",
      "Requirement already satisfied: typer>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (0.9.0)\r\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\r\n",
      "  Downloading kubernetes-30.1.0-py2.py3-none-any.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /opt/conda/lib/python3.10/site-packages (from chromadb) (8.2.3)\r\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (6.0.1)\r\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\r\n",
      "  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\r\n",
      "Requirement already satisfied: orjson>=3.9.12 in /opt/conda/lib/python3.10/site-packages (from chromadb) (3.10.6)\r\n",
      "Requirement already satisfied: httpx>=0.27.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (0.27.0)\r\n",
      "Requirement already satisfied: packaging>=19.1 in /opt/conda/lib/python3.10/site-packages (from build>=1.0.3->chromadb) (24.1)\r\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\r\n",
      "  Downloading pyproject_hooks-1.1.0-py3-none-any.whl.metadata (1.3 kB)\r\n",
      "Requirement already satisfied: tomli>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from build>=1.0.3->chromadb) (2.0.1)\r\n",
      "Requirement already satisfied: starlette<0.33.0,>=0.29.0 in /opt/conda/lib/python3.10/site-packages (from fastapi>=0.95.2->chromadb) (0.32.0.post1)\r\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb) (4.2.0)\r\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb) (2024.2.2)\r\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb) (1.0.5)\r\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb) (3.6)\r\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb) (1.3.0)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\r\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\r\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.26.1)\r\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.7.0)\r\n",
      "Requirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\r\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\r\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.26.18)\r\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\r\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\r\n",
      "Requirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\r\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (1.12.1)\r\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\r\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=6.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb) (6.11.0)\r\n",
      "Requirement already satisfied: backoff<3.0.0,>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (2.2.1)\r\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.62.0)\r\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.22.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.22.0)\r\n",
      "Requirement already satisfied: opentelemetry-proto==1.22.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.22.0)\r\n",
      "Collecting opentelemetry-instrumentation-asgi==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\r\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.46b0-py3-none-any.whl.metadata (1.9 kB)\r\n",
      "Collecting opentelemetry-instrumentation==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\r\n",
      "  Downloading opentelemetry_instrumentation-0.46b0-py3-none-any.whl.metadata (6.1 kB)\r\n",
      "Collecting opentelemetry-semantic-conventions==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\r\n",
      "  Downloading opentelemetry_semantic_conventions-0.46b0-py3-none-any.whl.metadata (2.3 kB)\r\n",
      "Collecting opentelemetry-util-http==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\r\n",
      "  Downloading opentelemetry_util_http-0.46b0-py3-none-any.whl.metadata (2.4 kB)\r\n",
      "Requirement already satisfied: setuptools>=16.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (69.0.3)\r\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\r\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\r\n",
      "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\r\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\r\n",
      "  Downloading opentelemetry_api-1.25.0-py3-none-any.whl.metadata (1.4 kB)\r\n",
      "INFO: pip is looking at multiple versions of opentelemetry-sdk to determine which version is compatible with other requirements. This could take a while.\r\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\r\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.45b0-py3-none-any.whl.metadata (2.0 kB)\r\n",
      "Collecting opentelemetry-instrumentation-asgi==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\r\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.45b0-py3-none-any.whl.metadata (1.9 kB)\r\n",
      "Collecting opentelemetry-instrumentation==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\r\n",
      "  Downloading opentelemetry_instrumentation-0.45b0-py3-none-any.whl.metadata (6.1 kB)\r\n",
      "Collecting opentelemetry-semantic-conventions==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\r\n",
      "  Downloading opentelemetry_semantic_conventions-0.45b0-py3-none-any.whl.metadata (2.2 kB)\r\n",
      "Collecting opentelemetry-util-http==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\r\n",
      "  Downloading opentelemetry_util_http-0.45b0-py3-none-any.whl.metadata (2.4 kB)\r\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\r\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.44b0-py3-none-any.whl.metadata (2.3 kB)\r\n",
      "Collecting opentelemetry-instrumentation-asgi==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\r\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.44b0-py3-none-any.whl.metadata (2.1 kB)\r\n",
      "Collecting opentelemetry-instrumentation==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\r\n",
      "  Downloading opentelemetry_instrumentation-0.44b0-py3-none-any.whl.metadata (6.1 kB)\r\n",
      "Collecting opentelemetry-semantic-conventions==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\r\n",
      "  Downloading opentelemetry_semantic_conventions-0.44b0-py3-none-any.whl.metadata (2.2 kB)\r\n",
      "Collecting opentelemetry-util-http==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\r\n",
      "  Downloading opentelemetry_util_http-0.44b0-py3-none-any.whl.metadata (2.4 kB)\r\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\r\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.43b0-py3-none-any.whl.metadata (2.3 kB)\r\n",
      "Collecting opentelemetry-instrumentation-asgi==0.43b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\r\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.43b0-py3-none-any.whl.metadata (2.1 kB)\r\n",
      "Collecting opentelemetry-instrumentation==0.43b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\r\n",
      "  Downloading opentelemetry_instrumentation-0.43b0-py3-none-any.whl.metadata (5.9 kB)\r\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.43b0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.43b0)\r\n",
      "Collecting opentelemetry-util-http==0.43b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\r\n",
      "  Downloading opentelemetry_util_http-0.43b0-py3-none-any.whl.metadata (2.5 kB)\r\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\r\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=1.9->chromadb) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic>=1.9->chromadb) (2.14.6)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.28->chromadb) (3.3.2)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from tokenizers>=0.13.2->chromadb) (0.23.2)\r\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer>=0.9.0->chromadb) (8.1.7)\r\n",
      "Requirement already satisfied: httptools>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\r\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\r\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\r\n",
      "Requirement already satisfied: watchfiles>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\r\n",
      "Requirement already satisfied: websockets>=10.4 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (12.0)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.2.4)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.3.0)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.3.1)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.0)\r\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\r\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\r\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\r\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.5.1)\r\n",
      "Downloading chromadb-0.5.3-py3-none-any.whl (559 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m559.5/559.5 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading bcrypt-4.1.3-cp39-abi3-manylinux_2_28_x86_64.whl (283 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading build-1.2.1-py3-none-any.whl (21 kB)\r\n",
      "Downloading kubernetes-30.1.0-py2.py3-none-any.whl (1.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading onnxruntime-1.18.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.43b0-py3-none-any.whl (11 kB)\r\n",
      "Downloading opentelemetry_instrumentation_asgi-0.43b0-py3-none-any.whl (14 kB)\r\n",
      "Downloading opentelemetry_instrumentation-0.43b0-py3-none-any.whl (28 kB)\r\n",
      "Downloading opentelemetry_util_http-0.43b0-py3-none-any.whl (6.9 kB)\r\n",
      "Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\r\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pyproject_hooks-1.1.0-py3-none-any.whl (9.2 kB)\r\n",
      "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\r\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: pypika\r\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53724 sha256=23f7fcf60e45847c6deffe2161ded96462c4d1481b3a46ef0b47a7dd61b0f768\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\r\n",
      "Successfully built pypika\r\n",
      "\u001b[33mWARNING: Error parsing requirements for nest-asyncio: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/nest_asyncio-1.5.8.dist-info/METADATA'\u001b[0m\u001b[33m\r\n",
      "\u001b[0mInstalling collected packages: pypika, monotonic, mmh3, pyproject_hooks, opentelemetry-util-http, humanfriendly, chroma-hnswlib, bcrypt, asgiref, posthog, coloredlogs, build, opentelemetry-instrumentation, onnxruntime, kubernetes, opentelemetry-instrumentation-asgi, opentelemetry-instrumentation-fastapi, chromadb\r\n",
      "  Attempting uninstall: kubernetes\r\n",
      "    Found existing installation: kubernetes 26.1.0\r\n",
      "    Uninstalling kubernetes-26.1.0:\r\n",
      "      Successfully uninstalled kubernetes-26.1.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "kfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\r\n",
      "kfp 2.5.0 requires kubernetes<27,>=8.0.0, but you have kubernetes 30.1.0 which is incompatible.\r\n",
      "kfp 2.5.0 requires requests-toolbelt<1,>=0.8.0, but you have requests-toolbelt 1.0.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed asgiref-3.8.1 bcrypt-4.1.3 build-1.2.1 chroma-hnswlib-0.7.3 chromadb-0.5.3 coloredlogs-15.0.1 humanfriendly-10.0 kubernetes-30.1.0 mmh3-4.1.0 monotonic-1.6 onnxruntime-1.18.1 opentelemetry-instrumentation-0.43b0 opentelemetry-instrumentation-asgi-0.43b0 opentelemetry-instrumentation-fastapi-0.43b0 opentelemetry-util-http-0.43b0 posthog-3.5.0 pypika-0.48.9 pyproject_hooks-1.1.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install LangChain -q\n",
    "!pip install -U langchain-community -q\n",
    "!pip install pypdf -q\n",
    "!pip install yt_dlp -q\n",
    "!pip install pydub -q\n",
    "!pip install unstructured -q\n",
    "!pip install docx2txt -q\n",
    "!pip install openai -q\n",
    "!pip install python-dotenv -q\n",
    "!pip install xlrd -q\n",
    "!pip install tiktoken -q\n",
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "635c2459",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T11:54:52.041298Z",
     "iopub.status.busy": "2024-07-06T11:54:52.040327Z",
     "iopub.status.idle": "2024-07-06T11:54:53.099218Z",
     "shell.execute_reply": "2024-07-06T11:54:53.098054Z"
    },
    "papermill": {
     "duration": 1.082873,
     "end_time": "2024-07-06T11:54:53.101834",
     "exception": false,
     "start_time": "2024-07-06T11:54:52.018961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import openai\n",
    "import os\n",
    "import numpy as np\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "user_secrets = UserSecretsClient()\n",
    "openai.api_key = user_secrets.get_secret(\"openai_api\")\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=openai.api_key,\n",
    ")\n",
    "\n",
    "llm_model = \"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b5991cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T11:54:53.181928Z",
     "iopub.status.busy": "2024-07-06T11:54:53.181427Z",
     "iopub.status.idle": "2024-07-06T11:54:53.696442Z",
     "shell.execute_reply": "2024-07-06T11:54:53.695197Z"
    },
    "papermill": {
     "duration": 0.538483,
     "end_time": "2024-07-06T11:54:53.698981",
     "exception": false,
     "start_time": "2024-07-06T11:54:53.160498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "embedding = OpenAIEmbeddings(openai_api_key=openai.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89efe54d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T11:54:53.782646Z",
     "iopub.status.busy": "2024-07-06T11:54:53.782231Z",
     "iopub.status.idle": "2024-07-06T11:54:53.787574Z",
     "shell.execute_reply": "2024-07-06T11:54:53.786436Z"
    },
    "papermill": {
     "duration": 0.028356,
     "end_time": "2024-07-06T11:54:53.789858",
     "exception": false,
     "start_time": "2024-07-06T11:54:53.761502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentence1 = \"My dog Rover likes to chase squirrels\"\n",
    "sentence2 = \"Fluffy my cat, refuses to eat from a can\"\n",
    "sentence3 = \"The chevy bolt accelerates to 60 mph in 6.7 seconds\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bf7011",
   "metadata": {
    "papermill": {
     "duration": 0.020435,
     "end_time": "2024-07-06T11:54:53.829944",
     "exception": false,
     "start_time": "2024-07-06T11:54:53.809509",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can then use the embedding class to create an embedding for each sentence. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f9473d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T11:54:53.870655Z",
     "iopub.status.busy": "2024-07-06T11:54:53.870250Z",
     "iopub.status.idle": "2024-07-06T11:54:55.470813Z",
     "shell.execute_reply": "2024-07-06T11:54:55.469451Z"
    },
    "papermill": {
     "duration": 1.624103,
     "end_time": "2024-07-06T11:54:55.473684",
     "exception": false,
     "start_time": "2024-07-06T11:54:53.849581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding1 = embedding.embed_query(sentence1)\n",
    "embedding2 = embedding.embed_query(sentence2)\n",
    "embedding3 = embedding.embed_query(sentence3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f29f2f31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T11:54:55.553603Z",
     "iopub.status.busy": "2024-07-06T11:54:55.553183Z",
     "iopub.status.idle": "2024-07-06T11:54:55.560456Z",
     "shell.execute_reply": "2024-07-06T11:54:55.559267Z"
    },
    "papermill": {
     "duration": 0.030783,
     "end_time": "2024-07-06T11:54:55.563049",
     "exception": false,
     "start_time": "2024-07-06T11:54:55.532266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The similarity between sentences one and two is 0.7994217224486891\n",
      "The similarity between sentences one and three is 0.7492779153935134\n",
      "The similarity between sentences two and three 0.6991800057325509\n"
     ]
    }
   ],
   "source": [
    "print('The similarity between sentences one and two is' , np.dot(embedding1, embedding2))\n",
    "print('The similarity between sentences one and three is' , np.dot(embedding1, embedding3))\n",
    "print('The similarity between sentences two and three' , np.dot(embedding2, embedding3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cfb3aad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T11:54:55.644075Z",
     "iopub.status.busy": "2024-07-06T11:54:55.643700Z",
     "iopub.status.idle": "2024-07-06T11:54:56.786097Z",
     "shell.execute_reply": "2024-07-06T11:54:56.784994Z"
    },
    "papermill": {
     "duration": 1.165777,
     "end_time": "2024-07-06T11:54:56.788666",
     "exception": false,
     "start_time": "2024-07-06T11:54:55.622889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# Load PDF\n",
    "loaders = [\n",
    "    # Duplicate documents on purpose - messy data\n",
    "    PyPDFLoader(\"/kaggle/input/machine-learning-lectures/MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(\"/kaggle/input/machine-learning-lectures/MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(\"/kaggle/input/machine-learning-lectures/MachineLearning-Lecture02.pdf\"),\n",
    "    PyPDFLoader(\"/kaggle/input/machine-learning-lectures/MachineLearning-Lecture03.pdf\")\n",
    "]\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14087073",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T11:54:56.869886Z",
     "iopub.status.busy": "2024-07-06T11:54:56.869087Z",
     "iopub.status.idle": "2024-07-06T11:54:56.895968Z",
     "shell.execute_reply": "2024-07-06T11:54:56.894885Z"
    },
    "papermill": {
     "duration": 0.050055,
     "end_time": "2024-07-06T11:54:56.898393",
     "exception": false,
     "start_time": "2024-07-06T11:54:56.848338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 150\n",
    ")\n",
    "\n",
    "splits = text_splitter.split_documents(docs)\n",
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "345874fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T11:54:57.020514Z",
     "iopub.status.busy": "2024-07-06T11:54:57.020090Z",
     "iopub.status.idle": "2024-07-06T11:54:58.099461Z",
     "shell.execute_reply": "2024-07-06T11:54:58.097868Z"
    },
    "papermill": {
     "duration": 1.104079,
     "end_time": "2024-07-06T11:54:58.102261",
     "exception": false,
     "start_time": "2024-07-06T11:54:56.998182",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "persist_directory = 'docs/chroma/'\n",
    "!rm -rf ./docs/chroma  # remove old database files if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34f8fd86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T11:54:58.182821Z",
     "iopub.status.busy": "2024-07-06T11:54:58.182417Z",
     "iopub.status.idle": "2024-07-06T11:55:03.177530Z",
     "shell.execute_reply": "2024-07-06T11:55:03.175732Z"
    },
    "papermill": {
     "duration": 5.020365,
     "end_time": "2024-07-06T11:55:03.181508",
     "exception": false,
     "start_time": "2024-07-06T11:54:58.161143",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209\n"
     ]
    }
   ],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory\n",
    ")\n",
    "\n",
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "653ca174",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T11:55:03.362171Z",
     "iopub.status.busy": "2024-07-06T11:55:03.361692Z",
     "iopub.status.idle": "2024-07-06T11:55:03.526151Z",
     "shell.execute_reply": "2024-07-06T11:55:03.524834Z"
    },
    "papermill": {
     "duration": 0.188442,
     "end_time": "2024-07-06T11:55:03.528705",
     "exception": false,
     "start_time": "2024-07-06T11:55:03.340263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are the names and emails of the course TA?\"\n",
    "docs = vectordb.similarity_search(question,k=3)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f1c2212",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T11:55:03.610988Z",
     "iopub.status.busy": "2024-07-06T11:55:03.610597Z",
     "iopub.status.idle": "2024-07-06T11:55:03.617575Z",
     "shell.execute_reply": "2024-07-06T11:55:03.616437Z"
    },
    "papermill": {
     "duration": 0.030851,
     "end_time": "2024-07-06T11:55:03.620049",
     "exception": false,
     "start_time": "2024-07-06T11:55:03.589198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"cs229-qa@cs.stanford.edu. This goes to an acc ount that's read by all the TAs and me. So \\nrather than sending us email individually, if you send email to this account, it will \\nactually let us get back to you maximally quickly with answers to your questions.  \\nIf you're asking questions about homework probl ems, please say in the subject line which \\nassignment and which question the email refers to, since that will also help us to route \\nyour question to the appropriate TA or to me  appropriately and get the response back to \\nyou quickly.  \\nLet's see. Skipping ahead — let's see — for homework, one midterm, one open and term \\nproject. Notice on the honor code. So one thi ng that I think will help you to succeed and \\ndo well in this class and even help you to enjoy this cla ss more is if you form a study \\ngroup.  \\nSo start looking around where you' re sitting now or at the end of class today, mingle a \\nlittle bit and get to know your classmates. I strongly encourage you to form study groups \\nand sort of have a group of people to study with and have a group of your fellow students \\nto talk over these concepts with. You can also  post on the class news group if you want to \\nuse that to try to form a study group.  \\nBut some of the problems sets in this cla ss are reasonably difficult.  People that have \\ntaken the class before may tell you they were very difficult. And just I bet it would be \\nmore fun for you, and you'd probably have a be tter learning experience if you form a\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f52da535",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T11:55:03.704058Z",
     "iopub.status.busy": "2024-07-06T11:55:03.703659Z",
     "iopub.status.idle": "2024-07-06T11:55:03.918457Z",
     "shell.execute_reply": "2024-07-06T11:55:03.917183Z"
    },
    "papermill": {
     "duration": 0.239545,
     "end_time": "2024-07-06T11:55:03.921175",
     "exception": false,
     "start_time": "2024-07-06T11:55:03.681630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "question = \"what did they say about matlab?\"\n",
    "docs = vectordb.similarity_search(question,k=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7abc7a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T11:55:04.004237Z",
     "iopub.status.busy": "2024-07-06T11:55:04.003218Z",
     "iopub.status.idle": "2024-07-06T11:55:04.010456Z",
     "shell.execute_reply": "2024-07-06T11:55:04.009254Z"
    },
    "papermill": {
     "duration": 0.03118,
     "end_time": "2024-07-06T11:55:04.012824",
     "exception": false,
     "start_time": "2024-07-06T11:55:03.981644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'page': 8, 'source': '/kaggle/input/machine-learning-lectures/MachineLearning-Lecture01.pdf'}, page_content='those homeworks will be done in either MATLA B or in Octave, which is sort of — I \\nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn\\'t.  \\nSo I guess for those of you that haven\\'t s een MATLAB before, and I know most of you \\nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \\nplot data. And it\\'s sort of an extremely easy to  learn tool to use for implementing a lot of \\nlearning algorithms.  \\nAnd in case some of you want to work on your  own home computer or something if you \\ndon\\'t have a MATLAB license, for the purposes of  this class, there\\'s also — [inaudible] \\nwrite that down [inaudible] MATLAB — there\\' s also a software package called Octave \\nthat you can download for free off the Internet. And it has somewhat fewer features than MATLAB, but it\\'s free, and for the purposes of  this class, it will work for just about \\neverything.  \\nSo actually I, well, so yeah, just a side comment for those of you that haven\\'t seen \\nMATLAB before I guess, once a colleague of mine at a different university, not at \\nStanford, actually teaches another machine l earning course. He\\'s taught it for many years. \\nSo one day, he was in his office, and an old student of his from, lik e, ten years ago came \\ninto his office and he said, \"Oh, professo r, professor, thank you so much for your')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98cb3986",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T11:55:04.055335Z",
     "iopub.status.busy": "2024-07-06T11:55:04.054874Z",
     "iopub.status.idle": "2024-07-06T11:55:04.062016Z",
     "shell.execute_reply": "2024-07-06T11:55:04.060804Z"
    },
    "papermill": {
     "duration": 0.03099,
     "end_time": "2024-07-06T11:55:04.064392",
     "exception": false,
     "start_time": "2024-07-06T11:55:04.033402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'page': 8, 'source': '/kaggle/input/machine-learning-lectures/MachineLearning-Lecture01.pdf'}, page_content='those homeworks will be done in either MATLA B or in Octave, which is sort of — I \\nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn\\'t.  \\nSo I guess for those of you that haven\\'t s een MATLAB before, and I know most of you \\nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \\nplot data. And it\\'s sort of an extremely easy to  learn tool to use for implementing a lot of \\nlearning algorithms.  \\nAnd in case some of you want to work on your  own home computer or something if you \\ndon\\'t have a MATLAB license, for the purposes of  this class, there\\'s also — [inaudible] \\nwrite that down [inaudible] MATLAB — there\\' s also a software package called Octave \\nthat you can download for free off the Internet. And it has somewhat fewer features than MATLAB, but it\\'s free, and for the purposes of  this class, it will work for just about \\neverything.  \\nSo actually I, well, so yeah, just a side comment for those of you that haven\\'t seen \\nMATLAB before I guess, once a colleague of mine at a different university, not at \\nStanford, actually teaches another machine l earning course. He\\'s taught it for many years. \\nSo one day, he was in his office, and an old student of his from, lik e, ten years ago came \\ninto his office and he said, \"Oh, professo r, professor, thank you so much for your')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88e61f51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T11:55:04.150022Z",
     "iopub.status.busy": "2024-07-06T11:55:04.149617Z",
     "iopub.status.idle": "2024-07-06T11:55:04.329054Z",
     "shell.execute_reply": "2024-07-06T11:55:04.327448Z"
    },
    "papermill": {
     "duration": 0.203866,
     "end_time": "2024-07-06T11:55:04.331643",
     "exception": false,
     "start_time": "2024-07-06T11:55:04.127777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 8, 'source': '/kaggle/input/machine-learning-lectures/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 8, 'source': '/kaggle/input/machine-learning-lectures/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 8, 'source': '/kaggle/input/machine-learning-lectures/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 8, 'source': '/kaggle/input/machine-learning-lectures/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 2, 'source': '/kaggle/input/machine-learning-lectures/MachineLearning-Lecture01.pdf'}\n"
     ]
    }
   ],
   "source": [
    "question = \"what did they say about supervised machine learning in the third lecture?\"\n",
    "docs = vectordb.similarity_search(question,k=5)\n",
    "for doc in docs:\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94677a22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T11:55:04.416919Z",
     "iopub.status.busy": "2024-07-06T11:55:04.416523Z",
     "iopub.status.idle": "2024-07-06T11:55:04.422363Z",
     "shell.execute_reply": "2024-07-06T11:55:04.421243Z"
    },
    "papermill": {
     "duration": 0.030903,
     "end_time": "2024-07-06T11:55:04.425285",
     "exception": false,
     "start_time": "2024-07-06T11:55:04.394382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So in this class, we've tried to convey to you a broad set of principl es and tools that will \n",
      "be useful for doing many, many things. And ev ery time I teach this class, I can actually \n",
      "very confidently say that af ter December, no matter what yo u're going to do after this \n",
      "December when you've sort of completed this  class, you'll find the things you learn in \n",
      "this class very useful, and these things will be useful pretty much no matter what you end \n",
      "up doing later in your life.  \n",
      "So I have more logistics to go over later, but let's say a few more words about machine \n",
      "learning. I feel that machine learning grew out of  early work in AI, early work in artificial \n",
      "intelligence. And over the last — I wanna say last 15 or last 20 years or so, it's been viewed as a sort of growing new capability for computers. And in particular, it turns out \n",
      "that there are many programs or there are many applications that you can't program by \n",
      "hand.  \n",
      "For example, if you want to get a computer to read handwritten characters, to read sort of \n",
      "handwritten digits, that actual ly turns out to be amazingly difficult to write a piece of \n",
      "software to take this input, an image of some thing that I wrote and to  figure out just what \n",
      "it is, to translate my cursive handwriting into — to extract the characters I wrote out in \n",
      "longhand. And other things: One thing that my students and I do is autonomous flight. It \n",
      "turns out to be extremely difficult to sit dow n and write a program to  fly a helicopter.\n"
     ]
    }
   ],
   "source": [
    "print(docs[4].page_content)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5344260,
     "sourceId": 8879570,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 232.061943,
   "end_time": "2024-07-06T11:55:05.754591",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-06T11:51:13.692648",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
